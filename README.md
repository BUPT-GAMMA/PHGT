# PHGT
Code for IJCAI'24: Heterogeneous Graph Transformer with Poly-Tokenization. 

This code is based on [HGB](https://github.com/THUDM/HGB) and [HINormer](https://github.com/Ffffffffire/HINormer)

# Requirement

- Python version == 3.9
- DGL version == 1.0.3
- cudatoolkit version == 11.3
- PyTorch version == 1.10

# Dataset

We use the same dataset as [HINormer](https://github.com/Ffffffffire/HINormer)

# Reproducibility

* We use the clusters generated by [SHGP](https://github.com/kepsail/SHGP)  to create global tokens. You can [download](https://drive.google.com/file/d/1befvVITj484ctfemV42_SrV91Fbudjd8/view?usp=sharing) the clusters we have generated and place them in the PHGT directory.
* Even when all random seeds are fixed, the experimental results will not be exactly the same each run. We suspect that this issue is caused by early versions DGL. However, the residual in each experiment should not exceed the standard deviation reported in the paper.
* Sometimes, the experiments may be numerically unstable (e.g., the normal F1 score is 0.9, but occasionally a result of 0.3 may appear). We ignore such results and rerun the experiment.

# Run Experiments

```
python run.py --config DBLP
```

# TODO
- [ ] We will update to a more readable version of the code.